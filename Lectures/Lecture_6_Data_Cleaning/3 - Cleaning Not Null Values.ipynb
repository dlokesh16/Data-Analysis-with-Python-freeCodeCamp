{"cells":[{"metadata":{},"cell_type":"markdown","source":"![rmotr](https://i.imgur.com/jiPp4hj.png)\n<hr style=\"margin-bottom: 40px;\">\n\n<img src=\"https://user-images.githubusercontent.com/7065401/39117173-a433bf6a-46e6-11e8-8a40-b4d4d6422493.jpg\"\n    style=\"width:300px; float: right; margin: 0 40px 40px 40px;\"></img>\n\n# Cleaning not-null values\n\nAfter dealing with many datasets I can tell you that \"missing data\" is not such a big deal. The best thing that can happen is to clearly see values like `np.nan`. The only thing you need to do is just use methods like `isnull` and `fillna`/`dropna` and pandas will take care of the rest.\n\nBut sometimes, you can have invalid values that are not just \"missing data\" (`None`, or `nan`). For example:"},{"metadata":{},"cell_type":"markdown","source":"![separator2](https://i.imgur.com/4gX5WFr.png)\n\n## Hands on!"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install numpy pandas","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting numpy\n  Downloading numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n\u001b[K     |████████████████████████████████| 15.3 MB 8.7 MB/s eta 0:00:01\n\u001b[?25hCollecting pandas\n  Downloading pandas-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n\u001b[K     |████████████████████████████████| 9.9 MB 37.7 MB/s eta 0:00:01\n\u001b[?25hCollecting pytz>=2017.3\n  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n\u001b[K     |████████████████████████████████| 510 kB 27.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\nInstalling collected packages: numpy, pytz, pandas\nSuccessfully installed numpy-1.20.1 pandas-1.2.2 pytz-2021.1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\n    'Sex': ['M', 'F', 'F', 'D', '?'],\n    'Age': [29, 30, 24, 290, 25],\n})\ndf","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"  Sex  Age\n0   M   29\n1   F   30\n2   F   24\n3   D  290\n4   ?   25","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>F</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>D</td>\n      <td>290</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>?</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The previous `DataFrame` doesn't have any \"missing value\", but clearly has invalid data. `290` doesn't seem like a valid age, and `D` and `?` don't correspond with any known sex category. How can you clean these not-missing, but clearly invalid values then?\n\n### Finding Unique Values\n\nThe first step to clean invalid values is to **notice** them, then **identify** them and finally handle them appropriately (remove them, replace them, etc). Usually, for a \"categorical\" type of field (like Sex, which only takes values of a discrete set `('M', 'F')`), we start by analyzing the variety of values present. For that, we use the `unique()` method:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Sex'].unique()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"array(['M', 'F', 'D', '?'], dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Sex'].value_counts()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"F    2\nD    1\n?    1\nM    1\nName: Sex, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Clearly if you see values like `'D'` or `'?'`, it'll immediately raise your attention. Now, what to do with them? Let's say you picked up the phone, called the survey company and they told you that `'D'` was a typo and it should actually be `F`. You can use the `replace` function to replace these values:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df['Sex'].replace('D', 'F')","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"0    M\n1    F\n2    F\n3    F\n4    ?\nName: Sex, dtype: object"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"It can accept a dictionary of values to replace. For example, they also told you that there might be a few `'N's`, that should actually be `'M's`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Sex'].replace({'D': 'F', 'N': 'M'})","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"0    M\n1    F\n2    F\n3    F\n4    ?\nName: Sex, dtype: object"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"If you have many columns to replace, you could apply it at \"DataFrame level\":"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.replace({\n    'Sex': {\n        'D': 'F',\n        'N': 'M'\n    },\n    'Age': {\n        290: 29\n    }\n})","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"  Sex  Age\n0   M   29\n1   F   30\n2   F   24\n3   F   29\n4   ?   25","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>F</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>F</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>?</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"In the previous example, I explicitly replaced 290 with 29 (assuming it was just an extra 0 entered at data-entry phase). But what if you'd like to remove all the extra 0s from the ages columns? (example, `150 > 15`, `490 > 49`).\n\nThe first step would be to just set the limit of the \"not possible\" age. Is it 100? 120? Let's say that anything above 100 isn't credible for **our** dataset. We can then combine boolean selection with the operation:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df[df['Age'] > 100]","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"  Sex  Age\n3   D  290","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>D</td>\n      <td>290</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"And we can now just divide by 10:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.loc[df['Age'] > 100, 'Age'] = df.loc[df['Age'] > 100, 'Age'] / 10","execution_count":10,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"  Sex   Age\n0   M  29.0\n1   F  30.0\n2   F  24.0\n3   D  29.0\n4   ?  25.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>30.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>F</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>D</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>?</td>\n      <td>25.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"![separator1](https://i.imgur.com/ZUWYTii.png)\n\n### Duplicates\n\nChecking duplicate values is extremely simple. It'll behave differently between Series and DataFrames. Let's start with Series. As an example, let's say we're throwing a fancy party and we're inviting Ambassadors from Europe. But can only invite one ambassador per country. This is our original list, and as you can see, both the UK and Germany have duplicated ambassadors:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ambassadors = pd.Series([\n    'France',\n    'United Kingdom',\n    'United Kingdom',\n    'Italy',\n    'Germany',\n    'Germany',\n    'Germany',\n], index=[\n    'Gérard Araud',\n    'Kim Darroch',\n    'Peter Westmacott',\n    'Armando Varricchio',\n    'Peter Wittig',\n    'Peter Ammon',\n    'Klaus Scharioth '\n])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ambassadors","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"Gérard Araud                  France\nKim Darroch           United Kingdom\nPeter Westmacott      United Kingdom\nArmando Varricchio             Italy\nPeter Wittig                 Germany\nPeter Ammon                  Germany\nKlaus Scharioth              Germany\ndtype: object"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The two most important methods to deal with duplicates are `duplicated` (that will tell you which values are duplicates) and `drop_duplicates` (which will just get rid of duplicates):"},{"metadata":{"trusted":true},"cell_type":"code","source":"ambassadors.duplicated()","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"Gérard Araud          False\nKim Darroch           False\nPeter Westmacott       True\nArmando Varricchio    False\nPeter Wittig          False\nPeter Ammon            True\nKlaus Scharioth        True\ndtype: bool"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"In this case `duplicated` didn't consider `'Kim Darroch'`, the first instance of the United Kingdom or `'Peter Wittig'` as duplicates. That's because, by default, it'll consider the first occurrence of the value as not-duplicate. You can change this behavior with the `keep` parameter:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ambassadors.duplicated(keep='last')","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"Gérard Araud          False\nKim Darroch            True\nPeter Westmacott      False\nArmando Varricchio    False\nPeter Wittig           True\nPeter Ammon            True\nKlaus Scharioth       False\ndtype: bool"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"In this case, the result is \"flipped\", `'Kim Darroch'` and `'Peter Wittig'` (the first ambassadors of their countries) are considered duplicates, but `'Peter Westmacott'` and `'Klaus Scharioth'` are not duplicates. You can also choose to mark all of them as duplicates with `keep=False`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ambassadors.duplicated(keep=False)","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"Gérard Araud          False\nKim Darroch            True\nPeter Westmacott       True\nArmando Varricchio    False\nPeter Wittig           True\nPeter Ammon            True\nKlaus Scharioth        True\ndtype: bool"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"A similar method is `drop_duplicates`, which just excludes the duplicated values and also accepts the `keep` parameter:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ambassadors.drop_duplicates()","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"Gérard Araud                  France\nKim Darroch           United Kingdom\nArmando Varricchio             Italy\nPeter Wittig                 Germany\ndtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ambassadors.drop_duplicates(keep='last')","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"Gérard Araud                  France\nPeter Westmacott      United Kingdom\nArmando Varricchio             Italy\nKlaus Scharioth              Germany\ndtype: object"},"metadata":{}}]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"ambassadors.drop_duplicates(keep=False)","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"Gérard Araud          France\nArmando Varricchio     Italy\ndtype: object"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Duplicates in DataFrames\n\nConceptually speaking, duplicates in a DataFrame happen at \"row\" level. Two rows with exactly the same values are considered to be duplicates:"},{"metadata":{"trusted":true},"cell_type":"code","source":"players = pd.DataFrame({\n    'Name': [\n        'Kobe Bryant',\n        'LeBron James',\n        'Kobe Bryant',\n        'Carmelo Anthony',\n        'Kobe Bryant',\n    ],\n    'Pos': [\n        'SG',\n        'SF',\n        'SG',\n        'SF',\n        'SF'\n    ]\n})","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"players","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"              Name Pos\n0      Kobe Bryant  SG\n1     LeBron James  SF\n2      Kobe Bryant  SG\n3  Carmelo Anthony  SF\n4      Kobe Bryant  SF","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Pos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kobe Bryant</td>\n      <td>SG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LeBron James</td>\n      <td>SF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kobe Bryant</td>\n      <td>SG</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Carmelo Anthony</td>\n      <td>SF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Kobe Bryant</td>\n      <td>SF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"In the previous DataFrame, we clearly see that Kobe is duplicated; but he appears with two different positions. What does `duplicated` say?"},{"metadata":{"trusted":true},"cell_type":"code","source":"players.duplicated()","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"0    False\n1    False\n2     True\n3    False\n4    False\ndtype: bool"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Again, conceptually, \"duplicated\" means \"all the column values should be duplicates\". We can customize this with the `subset` parameter:"},{"metadata":{"trusted":true},"cell_type":"code","source":"players.duplicated(subset=['Name'])","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"0    False\n1    False\n2     True\n3    False\n4     True\ndtype: bool"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"And the same rules of `keep` still apply:"},{"metadata":{"trusted":true},"cell_type":"code","source":"players.duplicated(subset=['Name'], keep='last')","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"0     True\n1    False\n2     True\n3    False\n4    False\ndtype: bool"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"`drop_duplicates` takes the same parameters:"},{"metadata":{"trusted":true},"cell_type":"code","source":"players.drop_duplicates()","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"              Name Pos\n0      Kobe Bryant  SG\n1     LeBron James  SF\n3  Carmelo Anthony  SF\n4      Kobe Bryant  SF","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Pos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kobe Bryant</td>\n      <td>SG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LeBron James</td>\n      <td>SF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Carmelo Anthony</td>\n      <td>SF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Kobe Bryant</td>\n      <td>SF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"players.drop_duplicates(subset=['Name'])","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"              Name Pos\n0      Kobe Bryant  SG\n1     LeBron James  SF\n3  Carmelo Anthony  SF","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Pos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kobe Bryant</td>\n      <td>SG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LeBron James</td>\n      <td>SF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Carmelo Anthony</td>\n      <td>SF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"players.drop_duplicates(subset=['Name'], keep='last')","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"              Name Pos\n1     LeBron James  SF\n3  Carmelo Anthony  SF\n4      Kobe Bryant  SF","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Pos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>LeBron James</td>\n      <td>SF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Carmelo Anthony</td>\n      <td>SF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Kobe Bryant</td>\n      <td>SF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"![separator1](https://i.imgur.com/ZUWYTii.png)\n\n### Text Handling\n\nCleaning text values can be incredibly hard. Invalid text values involves, 99% of the time, mistyping, which is completely unpredictable and doesn't follow any pattern. Thankfully, it's not so common these days, where data-entry tasks have been replaced by machines. Still, let's explore the most common cases:\n\n### Splitting Columns\n\nThe result of a survey is loaded and this is what you get:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\n    'Data': [\n        '1987_M_US _1',\n        '1990?_M_UK_1',\n        '1992_F_US_2',\n        '1970?_M_   IT_1',\n        '1985_F_I  T_2'\n]})","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"              Data\n0     1987_M_US _1\n1     1990?_M_UK_1\n2      1992_F_US_2\n3  1970?_M_   IT_1\n4    1985_F_I  T_2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1987_M_US _1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1990?_M_UK_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1992_F_US_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1970?_M_   IT_1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1985_F_I  T_2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"You know that the single columns represent the values \"year, Sex, Country and number of children\", but it's all been grouped in the same column and separated by an underscore. Pandas has a convenient method named `split` that we can use in these situations:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Data'].str.split('_')","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"0       [1987, M, US , 1]\n1       [1990?, M, UK, 1]\n2        [1992, F, US, 2]\n3    [1970?, M,    IT, 1]\n4      [1985, F, I  T, 2]\nName: Data, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Data'].str.split('_', expand=True)","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"       0  1      2  3\n0   1987  M    US   1\n1  1990?  M     UK  1\n2   1992  F     US  2\n3  1970?  M     IT  1\n4   1985  F   I  T  2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1987</td>\n      <td>M</td>\n      <td>US</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1990?</td>\n      <td>M</td>\n      <td>UK</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1992</td>\n      <td>F</td>\n      <td>US</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1970?</td>\n      <td>M</td>\n      <td>IT</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1985</td>\n      <td>F</td>\n      <td>I  T</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df['Data'].str.split('_', expand=True)","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = ['Year', 'Sex', 'Country', 'No Children']","execution_count":35,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can also check which columns contain a given value with the `contains` method:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"    Year Sex Country No Children\n0   1987   M     US            1\n1  1990?   M      UK           1\n2   1992   F      US           2\n3  1970?   M      IT           1\n4   1985   F    I  T           2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Sex</th>\n      <th>Country</th>\n      <th>No Children</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1987</td>\n      <td>M</td>\n      <td>US</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1990?</td>\n      <td>M</td>\n      <td>UK</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1992</td>\n      <td>F</td>\n      <td>US</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1970?</td>\n      <td>M</td>\n      <td>IT</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1985</td>\n      <td>F</td>\n      <td>I  T</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Year'].str.contains('\\?')","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"0    False\n1     True\n2    False\n3     True\n4    False\nName: Year, dtype: bool"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"[`contains`](http://pandas.pydata.org/pandas-docs/version/0.22.0/generated/pandas.Series.str.contains.html) takes a regex/pattern as first value, so we need to escape the `?` symbol as it has a special meaning for these patterns. Regular letters don't need escaping:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Country'].str.contains('U')","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"0     True\n1     True\n2     True\n3    False\n4    False\nName: Country, dtype: bool"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Removing blank spaces (like in `'US '` or `'I  T'` can be achieved with `strip` (`lstrip` and `rstrip` also exist) or just `replace`:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df['Country'].str.strip()","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"0      US\n1      UK\n2      US\n3      IT\n4    I  T\nName: Country, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Country'].str.replace(' ', '')","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"0    US\n1    UK\n2    US\n3    IT\n4    IT\nName: Country, dtype: object"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"As we said, `replace` and `contains` take regex patterns, which can make it easier to replace values in bulk:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df['Year'].str.replace(r'(?P<year>\\d{4})\\?', lambda m: m.group('year'))","execution_count":41,"outputs":[{"output_type":"stream","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n  \"\"\"Entry point for launching an IPython kernel.\n","name":"stderr"},{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"0    1987\n1    1990\n2    1992\n3    1970\n4    1985\nName: Year, dtype: object"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"But, be warned:\n\n> Some people, when confronted with a problem, think \"I know, I'll use regular expressions.\" Now they have two problems."},{"metadata":{},"cell_type":"markdown","source":"As you can see, all these string/text-related operations are applied over the `str` attribute of the series. That's because they have a special place in Series handling and you can read more about it [here](https://pandas.pydata.org/pandas-docs/stable/text.html)."},{"metadata":{},"cell_type":"markdown","source":"![separator2](https://i.imgur.com/4gX5WFr.png)"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}